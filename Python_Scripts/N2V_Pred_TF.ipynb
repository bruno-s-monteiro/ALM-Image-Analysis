{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d518ddf4-0927-47a7-a2c4-dc5a96884c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder path: D:/python_envs/Raw\n",
      "Model loaded successfully.\n",
      "Processing image: 2024.08.23- New EtOH 12h - zoom 2.lif - Field 2-1.tif\n",
      "Processing image: 2024.08.23- New EtOH 12h - zoom 2.lif - Field 3-1.tif\n",
      "Processing image: C4-2024.08.23- New EtOH 12h - zoom 2.lif - Field 1.tif\n",
      "The input image is of type uint8 and will be casted to float32 for prediction.\n",
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|█████▋                                                                                     | 1/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▍                                                                        | 2/16 [00:00<00:03,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████▌                                                                   | 3/16 [00:00<00:04,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████████▊                                                              | 4/16 [00:01<00:04,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|█████████████████████████▉                                                         | 5/16 [00:01<00:04,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████████████████████▏                                                   | 6/16 [00:02<00:04,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████████████████████████████████████▎                                              | 7/16 [00:02<00:04,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 8/16 [00:03<00:03,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████████████████████████████▋                                    | 9/16 [00:03<00:03,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|███████████████████████████████████████████████████▎                              | 10/16 [00:04<00:02,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████████████████████████████████▍                         | 11/16 [00:04<00:02,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████████████████████▌                    | 12/16 [00:05<00:01,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████████████████████████████████████▋               | 13/16 [00:05<00:01,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████████████████████████████████████████▊          | 14/16 [00:06<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████████████████████████████████████████▉     | 15/16 [00:06<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:07<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved denoised image to: D:/python_envs/Raw\\predictions\\C4-2024.08.23- New EtOH 12h - zoom 2.lif - Field 1_pred.tif\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script applies a denoising al to all TIF images in a selected folder using a pre-trained N2V model.\n",
    "\n",
    "### Key Features:\n",
    "1. **Folder Selection**: The user is prompted to select a folder containing `.tif` or `.tiff` images.\n",
    "2. **Model Loading**: A pre-trained N2V (Noise2Void) model is loaded to process the images.\n",
    "3. **Image Processing**: For each image in the selected folder, the denoising model is applied to reduce noise in the images.\n",
    "4. **Saving Results**: The denoised images are saved to a new folder called `predictions` within the same directory as the original images. Each denoised image is saved with `_pred` appended to the original filename.\n",
    "\n",
    "### Workflow:\n",
    "1. The user selects a folder containing `.tif` or `.tiff` files.\n",
    "2. The script processes each image using the N2V model to predict the denoised version.\n",
    "3. The denoised images are saved in a new sub-folder `predictions` with `_pred` appended to the filenames.\n",
    "\"\"\"\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from n2v.models import N2V\n",
    "from tifffile import imread\n",
    "import os\n",
    "from csbdeep.io import save_tiff_imagej_compatible\n",
    "\n",
    "# Function to prompt file selection for a directory\n",
    "def browse_folder():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the main window\n",
    "    folder_path = filedialog.askdirectory(title=\"Select a Folder with TIF Images\")\n",
    "    return folder_path\n",
    "\n",
    "# Prompt user for folder path containing images\n",
    "folder_path = browse_folder()\n",
    "print(f\"Folder path: {folder_path}\")\n",
    "\n",
    "# Get all .tif and .tiff files in the selected folder\n",
    "image_files = [f for f in os.listdir(folder_path) if f.endswith(('.tif', '.tiff'))]\n",
    "print(f\"Found {len(image_files)} image(s).\")\n",
    "\n",
    "# Create a \"predictions\" folder in the same directory if it doesn't exist\n",
    "predictions_folder = os.path.join(folder_path, \"N2V_Predictions\")\n",
    "if not os.path.exists(predictions_folder):\n",
    "    os.makedirs(predictions_folder)\n",
    "\n",
    "model_name = 'n2v_3D'\n",
    "basedir = 'D:/USERS/bm/model'\n",
    "\n",
    "# Load the previously trained model\n",
    "model = N2V(config=None, name=model_name, basedir=basedir)\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "# Iterate over all image files in the folder\n",
    "for img_file in image_files:\n",
    "    img_path = os.path.join(folder_path, img_file)\n",
    "    img = imread(img_path)\n",
    "    print(f\"Processing image: {img_file}\")\n",
    "\n",
    "    # Predict the denoised image\n",
    "    pred = model.predict(img, axes='ZYX', n_tiles=(2,4,4))\n",
    "\n",
    "    # Save the denoised image in the \"predictions\" folder with 'pred' appended to the original file name\n",
    "    pred_filename = f\"{os.path.splitext(img_file)[0]}_pred.tif\"\n",
    "    pred_path = os.path.join(predictions_folder, pred_filename)\n",
    "\n",
    "    # Check if the image is being saved\n",
    "    print(f\"Saving denoised image to: {pred_path}\")\n",
    "    save_tiff_imagej_compatible(pred_path, pred, 'ZYX')\n",
    "    print(f\"Saved denoised image: {pred_path}\")\n",
    "\n",
    "print(\"Denoising and saving completed for all images.\")\n",
    "# We import all our dependencies.\n",
    "from n2v.models import N2VConfig, N2V\n",
    "import numpy as np\n",
    "from csbdeep.utils import plot_history\n",
    "from n2v.utils.n2v_utils import manipulate_val_data\n",
    "from n2v.internals.N2V_DataGenerator import N2V_DataGenerator\n",
    "from matplotlib import pyplot as plt\n",
    "import urllib\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaa9b5fe-40f7-44b0-864a-6466275cc5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49db838-8e53-4230-8ffb-673623066abd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
